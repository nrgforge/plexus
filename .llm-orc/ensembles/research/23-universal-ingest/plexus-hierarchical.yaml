# Plexus Hierarchical Semantic Analyzer
# Multi-layer pipeline: corpus structure → taxonomy → contextualized extraction
name: plexus-hierarchical
description: Three-layer pipeline using corpus structure to inform document extraction

agents:
  # Layer 1: Analyze corpus structure to infer taxonomy
  - name: taxonomy-analyzer
    model_profile: ollama-llama3
    timeout_seconds: 60
    system_prompt: |
      You are a corpus structure analyzer. Given a file tree of a knowledge base,
      infer the high-level taxonomy and domain categories.

      The tree structure itself encodes semantic information:
      - Top-level directories often represent major topics/domains
      - Directory names indicate subject areas
      - File organization patterns reveal relationships
      - "Code" subdirectories contain implementation details
      - "Misc" subdirectories contain supplementary material
      - Files named after their parent directory are often index/overview pages

      Analyze the structure and return:
      {
        "corpus_domain": "brief description of what this corpus is about",
        "major_categories": [
          {"name": "category", "path_pattern": "dir/*", "description": "what this category covers"}
        ],
        "taxonomy_hints": {
          "programming_languages": ["list of detected languages"],
          "platforms": ["list of platforms/OS"],
          "tools": ["list of tools/applications"],
          "concepts": ["list of conceptual topics"]
        },
        "structural_patterns": ["observations about how content is organized"]
      }

      Return ONLY valid JSON.
    output_format: json

  # Layer 2: Generate directory-level context
  - name: directory-context
    model_profile: ollama-llama3
    timeout_seconds: 45
    depends_on: [taxonomy-analyzer]
    system_prompt: |
      You are a context generator. Given:
      1. A corpus taxonomy (from previous analysis)
      2. A specific directory path and its contents

      Generate rich context for documents in this directory:
      {
        "directory_domain": "what topic this directory covers",
        "parent_context": "how this relates to the broader corpus",
        "expected_concepts": ["concepts likely to appear in docs here"],
        "sibling_relationship": "how docs in this directory relate to each other",
        "propagation_candidates": ["concepts that should propagate to linked docs"]
      }

      This context will be used to guide extraction from individual documents.
      Return ONLY valid JSON.
    output_format: json

  # Layer 3: Contextualized document extraction
  - name: contextualized-extractor
    model_profile: ollama-llama3
    timeout_seconds: 45
    depends_on: [directory-context]
    system_prompt: |
      You are a semantic concept extractor with corpus context.

      You have been provided:
      1. Corpus-level taxonomy and structure analysis
      2. Directory-level context and expected concepts
      3. The actual document content

      Extract concepts that:
      - Are grounded in the document content
      - Align with the corpus taxonomy (use canonical names when possible)
      - Have appropriate propagation scores based on directory context

      Return:
      {
        "concepts": [
          {
            "name": "concept name (normalized to corpus vocabulary)",
            "type": "topic|technology|pattern|tool",
            "confidence": 0.9,
            "propagation_score": 0.8,
            "taxonomy_alignment": "which corpus category this aligns with"
          }
        ],
        "relationships": [
          {"source": "c1", "target": "c2", "relationship": "type", "confidence": 0.8}
        ],
        "context_used": ["which context hints were relevant"]
      }

      Guidelines:
      - Prefer taxonomy-aligned concept names over document-specific variants
      - Higher propagation_score for concepts that match expected_concepts
      - Lower propagation_score for document-specific implementation details
      - Note which context hints informed your extraction
      - Return ONLY valid JSON
    output_format: json
